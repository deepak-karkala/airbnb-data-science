{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features relevant to predicting price of a listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Country\", \"City\", \"State\", \"Neighbourhood Cleansed\", \n",
    "\"Host Since\", \"Host Response Time\", \"Host Response Rate\", \"Calculated host listings count\",\n",
    "\"Property Type\", \"Room Type\", \"Accommodates\", \"Bedrooms\", \"Beds\", \"Bed Type\",  \"Square Feet\", \"Cancellation Policy\",\n",
    "\"Minimum Nights\", \"Maximum Nights\", \"Has Availability\", \"Availability 30\", \"Availability 60\", \"Availability 90\", \"Availability 365\",\n",
    "\"Number of Reviews\", \"Reviews per Month\", \"First Review\", \"Last Review\", \"Review Scores Rating\", \"Review Scores Accuracy\", \"Review Scores Cleanliness\",\"Review Scores Checkin\", \"Review Scores Communication\", \"Review Scores Location\",\"Review Scores Value\",\n",
    "\"Features\",\n",
    "\"Amenities\",\n",
    "\"Price\"]\n",
    "\n",
    "# \"Neighbourhood Group Cleansed\",\n",
    "# \"Square Feet\": 97.56% of entries have NULL values => cannot be used\n",
    "# \"Calendar Updated\"\n",
    "# \"Weekly Price\", \"Monthly Price\", \"Security Deposit\", \"Cleaning Fee\", \"Guests Included\", \"Extra People\",\n",
    "\n",
    "features_new_host = [\"Country\", \"City\", \"Neighbourhood Cleansed\",\n",
    "                   \"Property Type\", \"Room Type\", \"Accommodates\",\"Bedrooms\", \"Beds\", \"Bed Type\", \"Cancellation Policy\",\n",
    "                   \"Minimum Nights\",\n",
    "                   \"Price\"]\n",
    "\n",
    "features_existing_host = [\"Country\", \"City\", \"Neighbourhood Cleansed\",\n",
    "                          \"Property Type\", \"Room Type\", \"Accommodates\", \"Bedrooms\", \"Beds\", \"Bed Type\", \"Cancellation Policy\",\n",
    "                          \"Minimum Nights\", \"Availability 30\", \"Availability 60\", \"Availability 90\", \"Availability 365\",\n",
    "                          \"Number of Reviews\", \"Reviews per Month\", \"Review Scores Rating\", \"Review Scores Accuracy\", \"Review Scores Cleanliness\",\"Review Scores Checkin\", \"Review Scores Communication\", \"Review Scores Location\",\"Review Scores Value\",\n",
    "                          \"Host Since\", \"Host Response Time\", \"Host Response Rate\", \"Calculated host listings count\",\n",
    "                          \"Price\"]\n",
    "\n",
    "############################################\n",
    "########## Feature pre-processing ##########\n",
    "#### Numerical (Input text fields)\n",
    "# \"Minimum Nights\", \"Availability 30\", \"Availability 60\", \"Availability 90\", \"Availability 365\"\n",
    "# \"Number of Reviews\", \n",
    "# Review Scores Rating(20-100)\n",
    "# \"Host Since\" (num_days = current_date - host_since_date), Host Response Rate(0-100), \"Calculated host listings count\"\n",
    "# Price (Convert from local currency to USD)\n",
    "\n",
    "#### Numerical (Dropdown numerical values)\n",
    "# Accommodates(1-16), \"Bedrooms\"(0-10), \"Beds\"(0-16)\n",
    "# \"Review Scores Accuracy(2-10)\", \"Review Scores Cleanliness(2-10)\",\"Review Scores Checkin(2-10)\", \"Review Scores Communication(2-10)\", \"Review Scores Location(2-10)\",\"Review Scores Value(2-10)\"\n",
    "\n",
    "#### Label encoding (0, 1, 2 .... n_categories-1) (Category dropdowns -> on user select must be assigned numerical value)\n",
    "# \"Country\", \"City\", \"Neighbourhood Cleansed\"\n",
    "# \"Property Type\", \"Room Type\", \"Bed Type\", \"Cancellation Policy\"\n",
    "# \"Host Response Time\"\n",
    "############################################\n",
    "\n",
    "\n",
    "# TODO\n",
    "# Host since -> convert to days ----------------------------------- Done\n",
    "# Features -> Extract features  ----------------------------------- Done\n",
    "# Amenities -> Extract features ----------------------------------- Done\n",
    "# Price -> Convert to local currency\n",
    "# Verify missing features (Listing type etc...) ------------------- Done\n",
    "# Decide what plots to be shown in exploratory analysis section ---\n",
    "# Flask vs Flast + React ------------------------------------------ Done (Flask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nesara/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (66) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Neighbourhood Cleansed</th>\n",
       "      <th>Host Since</th>\n",
       "      <th>Host Response Time</th>\n",
       "      <th>Host Response Rate</th>\n",
       "      <th>Calculated host listings count</th>\n",
       "      <th>Property Type</th>\n",
       "      <th>Room Type</th>\n",
       "      <th>...</th>\n",
       "      <th>Review Scores Rating</th>\n",
       "      <th>Review Scores Accuracy</th>\n",
       "      <th>Review Scores Cleanliness</th>\n",
       "      <th>Review Scores Checkin</th>\n",
       "      <th>Review Scores Communication</th>\n",
       "      <th>Review Scores Location</th>\n",
       "      <th>Review Scores Value</th>\n",
       "      <th>Features</th>\n",
       "      <th>Amenities</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Noord-Holland</td>\n",
       "      <td>Watergraafsmeer</td>\n",
       "      <td>2017-03-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Host Has Profile Pic</td>\n",
       "      <td>TV,Kitchen,Heating,Washer,Smoke detector,Lapto...</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Noord-Holland</td>\n",
       "      <td>Watergraafsmeer</td>\n",
       "      <td>2014-10-21</td>\n",
       "      <td>within a day</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>House</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>...</td>\n",
       "      <td>94.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Host Has Profile Pic,Host Identity Verified,Is...</td>\n",
       "      <td>TV,Wireless Internet,Kitchen,Heating,Family/ki...</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country       City          State Neighbourhood Cleansed  Host Since  \\\n",
       "0  Netherlands  Amsterdam  Noord-Holland        Watergraafsmeer  2017-03-28   \n",
       "1  Netherlands  Amsterdam  Noord-Holland        Watergraafsmeer  2014-10-21   \n",
       "\n",
       "  Host Response Time  Host Response Rate  Calculated host listings count  \\\n",
       "0                NaN                 NaN                             1.0   \n",
       "1       within a day               100.0                             1.0   \n",
       "\n",
       "  Property Type        Room Type  ...    Review Scores Rating  \\\n",
       "0     Apartment  Entire home/apt  ...                     NaN   \n",
       "1         House  Entire home/apt  ...                    94.0   \n",
       "\n",
       "   Review Scores Accuracy  Review Scores Cleanliness Review Scores Checkin  \\\n",
       "0                     NaN                        NaN                   NaN   \n",
       "1                     9.0                        9.0                  10.0   \n",
       "\n",
       "   Review Scores Communication Review Scores Location  Review Scores Value  \\\n",
       "0                          NaN                    NaN                  NaN   \n",
       "1                          9.0                   10.0                  9.0   \n",
       "\n",
       "                                            Features  \\\n",
       "0                               Host Has Profile Pic   \n",
       "1  Host Has Profile Pic,Host Identity Verified,Is...   \n",
       "\n",
       "                                           Amenities  Price  \n",
       "0  TV,Kitchen,Heating,Washer,Smoke detector,Lapto...   80.0  \n",
       "1  TV,Wireless Internet,Kitchen,Heating,Family/ki...  195.0  \n",
       "\n",
       "[2 rows x 37 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/airbnb-data-science/airbnb-listings.csv\", usecols=columns, sep=';')\n",
    "df = df[columns]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "485419"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfo = df.copy()\n",
    "len(dfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Existing hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = dfo.copy()\n",
    "df = dfo[features_existing_host].copy()\n",
    "\n",
    "enable_separate_features = 0\n",
    "enable_separate_amenities = 0\n",
    "\n",
    "########################################################\n",
    "############ Location Features #############\n",
    "###### Countries ######## \n",
    "# Remove countries with very few entries\n",
    "exclude_low_count_countries_list = [\"0\", \"Cuba\", \"Mexico\", \"Uruguay\", \"Vanuatu\", \"Vatican City\"]\n",
    "df = df[~df[\"Country\"].isin(exclude_low_count_countries_list)]\n",
    "# Remove null (3 entries)\n",
    "df = df[~pd.isnull(df[\"Country\"])]\n",
    "\n",
    "###### City ######## \n",
    "# Remove cities with less than 10 listings \n",
    "# (Total over 4000 cities, 800 odd unique cities with more than 10 listings)\n",
    "df = df.groupby(\"City\").filter(lambda x: len(x)>10)\n",
    "# Remove null (451 entries)\n",
    "df = df[~pd.isnull(df[\"City\"])]\n",
    "\n",
    "\n",
    "###### Neighbourhood Cleansed ######\n",
    "# Remove integer Neighbourhood names\n",
    "df = df[df.apply(lambda x: not x[\"Neighbourhood Cleansed\"].startswith(\"7\"), axis=1)].copy()\n",
    "# Remove Neighbourhood with less than 10 listings \n",
    "# (Total over 2200 cities, 1500 odd unique cities with more than 10 listings)\n",
    "df = df.groupby(\"Neighbourhood Cleansed\").filter(lambda x: len(x)>10)\n",
    "\n",
    "# Remove null (1 entry)\n",
    "df = df[~pd.isnull(df[\"Neighbourhood Cleansed\"])]\n",
    "#######################################################\n",
    "\n",
    "\n",
    "####################################################################\n",
    "############ Basic (Beds, Area, Cancellation) Features #############\n",
    "\n",
    "###### Property Type #####\n",
    "# Remove null (11 entries)\n",
    "df = df[~pd.isnull(df[\"Property Type\"])]\n",
    "# Remove types with less than 10 entries\n",
    "df = df.groupby(\"Property Type\").filter(lambda x: len(x)>=10)\n",
    "\n",
    "###### Room Type #####\n",
    "# Remove null (1 entries)\n",
    "df = df[~pd.isnull(df[\"Room Type\"])]\n",
    "\n",
    "###### Accommodates #####\n",
    "# Remove null (63 entries)\n",
    "df = df[~pd.isnull(df[\"Accommodates\"])]\n",
    "# Accommodate maximum 16 people\n",
    "df = df[df[\"Accommodates\"] <= 16]\n",
    "\n",
    "###### Bedrooms #########\n",
    "# Remove null (597 entries)\n",
    "df = df[~pd.isnull(df[\"Bedrooms\"])]\n",
    "# Remove more than 10 bedrooms\n",
    "df = df[df[\"Bedrooms\"] <= 10]\n",
    "\n",
    "###### Beds #########\n",
    "# Remove null (903 entries)\n",
    "df = df[~pd.isnull(df[\"Beds\"])]\n",
    "# Remove more than 16 beds (2 entries)\n",
    "df = df[df[\"Beds\"] <= 16]\n",
    "\n",
    "###### Bed Type #########\n",
    "# Remove null (1 entry)\n",
    "df = df[~pd.isnull(df[\"Bed Type\"])]\n",
    "\n",
    "###### Cancellation Policy #########\n",
    "# Remove cancellation policy with low entries (3)\n",
    "exclude_cancellation_policy_list = [\"long_term\", \"no_refunds\"]\n",
    "df = df[~df[\"Cancellation Policy\"].isin(exclude_cancellation_policy_list)]\n",
    "# Remove null (2 entries)\n",
    "df = df[~pd.isnull(df[\"Cancellation Policy\"])]\n",
    "####################################################################\n",
    "\n",
    "\n",
    "##########################################################\n",
    "######### Availability #########\n",
    "\n",
    "###### Minimum Nights #########\n",
    "# Remove \"Minimum Nights\" above 30 except for multiples of 30 (corresponding to months)\n",
    "df = df[(df[\"Minimum Nights\"]<=31) | (df[\"Minimum Nights\"].isin([60, 90, 120, 180]))]\n",
    "# Remove null (2 entries)\n",
    "df = df[~pd.isnull(df[\"Minimum Nights\"])]\n",
    "\n",
    "###### Availability 30 #########\n",
    "# Remove null (2 entries)\n",
    "df = df[~pd.isnull(df[\"Availability 30\"])]\n",
    "\n",
    "###### Availability 60 #########\n",
    "# Remove null (2 entries)\n",
    "df = df[~pd.isnull(df[\"Availability 60\"])]\n",
    "\n",
    "###### Availability 90 #########\n",
    "# Remove null (2 entries)\n",
    "df = df[~pd.isnull(df[\"Availability 90\"])]\n",
    "\n",
    "###### Availability 365 #########\n",
    "# Remove null (2 entries)\n",
    "df = df[~pd.isnull(df[\"Availability 365\"])]\n",
    "##########################################################\n",
    "\n",
    "\n",
    "##########################################################\n",
    "######### Reviews #########\n",
    "\n",
    "###### Number of Reviews #########\n",
    "# Remove entries with 0 reviews (Use Model for new host in this case)\n",
    "df = df[df[\"Number of Reviews\"] > 0]\n",
    "# Remove null (2 entries)\n",
    "df = df[~pd.isnull(df[\"Number of Reviews\"])]\n",
    "\n",
    "###### Reviews per Month #########\n",
    "#df.at[(df[\"Number of Reviews\"]==0) & (df[pd.isnull(\"Reviews per Month\")]), \"Reviews per Month\"] = 0\n",
    "# Remove null (235 entries)\n",
    "df = df[~pd.isnull(df[\"Reviews per Month\"])]\n",
    "\n",
    "##### Reviews Scores #############\n",
    "df = df[~pd.isnull(df[\"Review Scores Rating\"])]\n",
    "df = df[~pd.isnull(df[\"Review Scores Accuracy\"])]\n",
    "df = df[~pd.isnull(df[\"Review Scores Cleanliness\"])]\n",
    "df = df[~pd.isnull(df[\"Review Scores Checkin\"])]\n",
    "df = df[~pd.isnull(df[\"Review Scores Communication\"])]\n",
    "df = df[~pd.isnull(df[\"Review Scores Location\"])]\n",
    "df = df[~pd.isnull(df[\"Review Scores Value\"])]\n",
    "##########################################################\n",
    "\n",
    "\n",
    "\n",
    "##########################################################\n",
    "######### Host Features #########\n",
    "\n",
    "###### Host Since #########\n",
    "# Remove null (504 entries)\n",
    "df = df[~pd.isnull(df[\"Host Since\"])]\n",
    "\n",
    "# Convert date to number of days till today\n",
    "today_date = pd.to_datetime(pd.to_datetime(\"today\").date())\n",
    "df[\"Host Since\"] = pd.to_datetime(df[\"Host Since\"])\n",
    "df[\"Host Since Days\"] = (today_date - df[\"Host Since\"])\n",
    "df['Host Since Days'] = df[['Host Since Days']].apply(pd.to_numeric)\n",
    "df['Host Since Days'] = df['Host Since Days'] / (24*60*60*1e9) #np.timedelta64(1, 'D')\n",
    "df[\"Host Since Days\"] = df[\"Host Since Days\"].astype(int)\n",
    "\n",
    "###### Host Response Time #####\n",
    "# Assign \"a few days or more\" to entries with NULL values for \"Host Response Time\"\n",
    "df.at[pd.isnull(df[\"Host Response Time\"]), \"Host Response Time\"] = \"a few days or more\"\n",
    "\n",
    "###### Host Response Rate #####\n",
    "# Assign mean(93.4) to entries with NULL values for \"Host Response Rate\"\n",
    "df.at[pd.isnull(df[\"Host Response Rate\"]), \"Host Response Rate\"] = dfo[\"Host Response Rate\"].mean()\n",
    "\n",
    "###### Calculated host listings count #####\n",
    "# Assign 1 to entries with NULL values for \"Calculated host listings count\"\n",
    "df.at[pd.isnull(df[\"Calculated host listings count\"]), \"Calculated host listings count\"] = 1\n",
    "##########################################################\n",
    "\n",
    "\n",
    "\n",
    "##########################################################\n",
    "######### Extract Features #########\n",
    "\"\"\"\n",
    "features_list = []\n",
    "for i in range(len(df[\"Features\"].unique())):\n",
    "    if not pd.isnull(df[\"Features\"].unique()[i]):\n",
    "        features = df[\"Features\"].unique()[i].split(\",\")\n",
    "        for ft in features:\n",
    "            if ft not in features_list:\n",
    "                features_list.append(ft)\n",
    "\"\"\"\n",
    "\n",
    "features_list = ['Host Has Profile Pic',\n",
    "                 'Host Identity Verified',\n",
    "                 'Is Location Exact',\n",
    "                 'Instant Bookable',\n",
    "                 'Host Is Superhost',\n",
    "                 'Require Guest Phone Verification',\n",
    "                 'Require Guest Profile Picture',\n",
    "                 'Requires License']\n",
    "\n",
    "# Assign 0 to all the above features\n",
    "for i in range(len(features_list)):\n",
    "    ft = features_list[i]\n",
    "    df[ft] = 0\n",
    "\n",
    "\n",
    "if enable_separate_features == 1:\n",
    "    # Assign 1 if that feature is present\n",
    "    for i in range(len(df)):\n",
    "        idx = df.index[i]\n",
    "        features = df.loc[idx][\"Features\"]\n",
    "        if not pd.isnull(features):\n",
    "            features = features.split(\",\")\n",
    "            for ft in features:\n",
    "                df.at[idx, ft] = 1\n",
    "##########################################################\n",
    "\n",
    "\n",
    "\n",
    "##########################################################\n",
    "######### Extract Amenities #########\n",
    "\"\"\"\n",
    "amenities_list = []\n",
    "for i in range(len(df[\"Amenities\"].unique())):\n",
    "    if not pd.isnull(df[\"Amenities\"].unique()[i]):\n",
    "        amenities = df[\"Amenities\"].unique()[i].split(\",\")\n",
    "        for ft in amenities:\n",
    "            if ft not in amenities_list:\n",
    "                amenities_list.append(ft)\n",
    "amenities_list\n",
    "\"\"\"\n",
    "amenities_list = ['TV',\n",
    "                 'Wireless Internet',\n",
    "                 'Kitchen',\n",
    "                 'Heating',\n",
    "                 'Family/kid friendly',\n",
    "                 'Washer',\n",
    "                 'Smoke detector',\n",
    "                 'Fire extinguisher',\n",
    "                 'Essentials',\n",
    "                 'Cable TV',\n",
    "                 'Internet',\n",
    "                 'Dryer',\n",
    "                 'First aid kit',\n",
    "                 'Safety card',\n",
    "                 'Shampoo',\n",
    "                 'Hangers',\n",
    "                 'Laptop friendly workspace',\n",
    "                 'Air conditioning',\n",
    "                 'Breakfast',\n",
    "                 'Free parking on premises',\n",
    "                 'Elevator in building',\n",
    "                 'Buzzer/wireless intercom',\n",
    "                 'Hair dryer',\n",
    "                 'Private living room',\n",
    "                 'Iron',\n",
    "                 'Wheelchair accessible',\n",
    "                 'Hot tub',\n",
    "                 'Carbon monoxide detector',\n",
    "                 '24-hour check-in',\n",
    "                 'Pets live on this property',\n",
    "                 'Dog(s)',\n",
    "                 'Gym',\n",
    "                 'Lock on bedroom door',\n",
    "                 'Private entrance',\n",
    "                 'Indoor fireplace',\n",
    "                 'Smoking allowed',\n",
    "                 'Pets allowed',\n",
    "                 'Cat(s)',\n",
    "                 'Self Check-In',\n",
    "                 'Doorman Entry',\n",
    "                 'Suitable for events',\n",
    "                 'Pool',\n",
    "                 'Lockbox',\n",
    "                 'Bathtub',\n",
    "                 'Room-darkening shades',\n",
    "                 'Game console',\n",
    "                 'Doorman',\n",
    "                 'High chair',\n",
    "                 'Pack ’n Play/travel crib',\n",
    "                 'Keypad',\n",
    "                 'Other pet(s)',\n",
    "                 'Smartlock']\n",
    "\n",
    "# Assign 0 to all the above amenities\n",
    "for i in range(len(amenities_list)):\n",
    "    ft = amenities_list[i]\n",
    "    df[ft] = 0\n",
    "\n",
    "    \n",
    "if enable_separate_amenities == 1:\n",
    "    # Assign 1 if those amenities are present\n",
    "    for i in range(len(df)):\n",
    "        idx = df.index[i]\n",
    "        amenities = df.loc[idx][\"Amenities\"]\n",
    "        if not pd.isnull(amenities):\n",
    "            amenities = amenities.split(\",\")\n",
    "            for ft in amenities:\n",
    "                df.at[idx, ft] = 1              \n",
    "##########################################################\n",
    "\n",
    "\n",
    "\n",
    "##########################################################\n",
    "######### Price (Output variable) #########\n",
    "\n",
    "\n",
    "### TODO: Convert to local currency\n",
    "\n",
    "# Remove null (7954 entries)\n",
    "df = df[~pd.isnull(df[\"Price\"])]\n",
    "# Remove 0 (4 entries)\n",
    "df = df[df[\"Price\"] > 0]\n",
    "\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337588"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>Neighbourhood Cleansed</th>\n",
       "      <th>Property Type</th>\n",
       "      <th>Room Type</th>\n",
       "      <th>Accommodates</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Beds</th>\n",
       "      <th>Bed Type</th>\n",
       "      <th>Cancellation Policy</th>\n",
       "      <th>...</th>\n",
       "      <th>Lockbox</th>\n",
       "      <th>Bathtub</th>\n",
       "      <th>Room-darkening shades</th>\n",
       "      <th>Game console</th>\n",
       "      <th>Doorman</th>\n",
       "      <th>High chair</th>\n",
       "      <th>Pack ’n Play/travel crib</th>\n",
       "      <th>Keypad</th>\n",
       "      <th>Other pet(s)</th>\n",
       "      <th>Smartlock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Watergraafsmeer</td>\n",
       "      <td>House</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>strict</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Watergraafsmeer</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Real Bed</td>\n",
       "      <td>moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country       City Neighbourhood Cleansed Property Type  \\\n",
       "1  Netherlands  Amsterdam        Watergraafsmeer         House   \n",
       "2  Netherlands  Amsterdam        Watergraafsmeer     Apartment   \n",
       "\n",
       "         Room Type  Accommodates  Bedrooms  Beds  Bed Type  \\\n",
       "1  Entire home/apt           4.0       4.0   5.0  Real Bed   \n",
       "2  Entire home/apt           4.0       2.0   2.0  Real Bed   \n",
       "\n",
       "  Cancellation Policy    ...      Lockbox  Bathtub  Room-darkening shades  \\\n",
       "1              strict    ...            0        0                      0   \n",
       "2            moderate    ...            0        0                      0   \n",
       "\n",
       "   Game console  Doorman  High chair  Pack ’n Play/travel crib  Keypad  \\\n",
       "1             0        0           0                         0       0   \n",
       "2             0        0           0                         0       0   \n",
       "\n",
       "   Other pet(s)  Smartlock  \n",
       "1             0          0  \n",
       "2             0          0  \n",
       "\n",
       "[2 rows x 90 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Price Categories (in USD)\n",
    "# 1:10-50 2:50-75 3:75-100 4:100-150 5:150-200 6:>200\n",
    "df[\"Price Label\"] = pd.cut(df[\"Price\"],\n",
    "                           bins=[0., 50., 75., 100.0, 150., 200., np.inf],\n",
    "                           labels=[1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# Distribution of class labels in overall dataset\n",
    "# df[\"Price Label\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "del df[\"index\"]\n",
    "\n",
    "\"\"\"\n",
    "dfx = df.copy()\n",
    "del dfx[\"Price\"]\n",
    "dfy = df[\"Price\"].copy()\n",
    "x_train, x_test, y_train, y_test = train_test_split(dfx,dfy, test_size=0.1, random_state=42)\n",
    "\"\"\"\n",
    "\n",
    "# Stratified split\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
    "for train_index, test_index in split.split(df, df[\"Price Label\"]):\n",
    "    strat_train_set = df.loc[train_index]\n",
    "    strat_test_set = df.loc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate, scatter matrix analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_strat_train = strat_train_set.copy()\n",
    "\n",
    "#from pandas.plotting import scatter_matrix\n",
    "#attributes = [\"Review Scores Rating\", \"Price\"]\n",
    "#scatter_matrix(df[attributes], figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data for Machine Learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop labels for training set\n",
    "df = strat_train_set.drop(\"Price Label\", axis=1) \n",
    "df_labels = strat_train_set[\"Price Label\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Check if there are any rows with NULL values\n",
    "sample_incomplete_rows = df[df.isnull().any(axis=1)] #.head()\n",
    "len(sample_incomplete_rows)\n",
    "\n",
    "# Option 1: Remove rows with NULL values for any subset of columns\n",
    "# sample_incomplete_rows.dropna(subset=[\"Bedrooms\"])\n",
    "\n",
    "# Option 2: Remove columns with NULL values\n",
    "# sample_incomplete_rows.drop(\"Bedrooms\", axis=1)\n",
    "\n",
    "# Option 3: Fill NULL values with median values of corresponding columns\n",
    "\n",
    "### Method 1: Manual\n",
    "# median = df[\"Bedrooms\"].median()\n",
    "# sample_incomplete_rows[\"Bedrooms\"].fillna(median, inplace=True)\n",
    "\n",
    "### Method 2: sklearn in-built (Works when all numerical columns NULL is to be replaced with median)\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "# Select numerical columns only\n",
    "df_num = df_xtrain.select_dtypes(include=[np.number])\n",
    "imputer.fit(df_num)\n",
    "X = imputer.transform(df_num)\n",
    "Xtrain = pd.DataFrame(X, columns=df_num.columns,\n",
    "                          index=df_num.index)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding extra features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def add_extra_features(X, add_bedrooms_per_room=True):\n",
    "    rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
    "    population_per_household = X[:, population_ix] / X[:, household_ix]\n",
    "    if add_bedrooms_per_room:\n",
    "        bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "        return np.c_[X, rooms_per_household, population_per_household,\n",
    "                     bedrooms_per_room]\n",
    "    else:\n",
    "        return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "attr_adder = FunctionTransformer(add_extra_features, validate=False,\n",
    "                                 kw_args={\"add_bedrooms_per_room\": False})\n",
    "df_extra_attribs = attr_adder.fit_transform(df.values)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined pipeline for both numerical and categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "##########################################################\n",
    "############ Pipeline for numerical features #############\n",
    "# Select numerical columns only\n",
    "df_num = df.select_dtypes(include=[np.number])\n",
    "numerical_pipeline = Pipeline([\n",
    "        #('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        #('attribs_adder', FunctionTransformer(add_extra_features, validate=False)),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "#df_num_tr = numerical_pipeline.fit_transform(df_num)\n",
    "#df_num_tr\n",
    "##########################################################\n",
    "\n",
    "\n",
    "##########################################################\n",
    "########## Pipeline for categorical features #############\n",
    "categorical_columns = [\"Country\", \"City\", \"Neighbourhood Cleansed\",\n",
    "                    \"Property Type\", \"Room Type\", \"Bed Type\", \"Cancellation Policy\",\n",
    "                    \"Host Response Time\"]\n",
    "#df_cat = df[categorical_columns]\n",
    "\n",
    "# Encode categorical features as integers\n",
    "# ordinal_encoder = OrdinalEncoder()\n",
    "# df_cat_encoded = ordinal_encoder.fit_transform(df_cat)\n",
    "##########################################################\n",
    "\n",
    "\n",
    "##########################################################\n",
    "########## Combined Pipeline for all features ############\n",
    "numerical_attribs = list(df_num)  \n",
    "categorical_attribs = categorical_columns\n",
    "\n",
    "preprocessing_pipeline = ColumnTransformer([\n",
    "        (\"numerical\", numerical_pipeline, numerical_attribs),\n",
    "        (\"categorical\", OrdinalEncoder(), categorical_attribs),\n",
    "    ])\n",
    "\n",
    "df_prepared = preprocessing_pipeline.fit_transform(df)\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303829, 89)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model training and selection pipeline\n",
    "\n",
    "# Model selection\n",
    "## For each ML Model\n",
    "#### 1. Use Grid Search or Randomized search to find best parameters (get_hyperparameter_search_results)\n",
    "#### 2. Plots to show how CV mean score varies by varying different parameters\n",
    "####        For each parameter being searched, fix all but one parameter, plot rmse vs one varying parameter\n",
    "#### 3. Plots to show feature importance\n",
    "#### 4. Save best estimator\n",
    "\n",
    "# Model comparison\n",
    "## For each ML Model\n",
    "#### 1. Get test RMSE results, mean, SE, 95%_ci etc (get_test_results)\n",
    "## Visualise models (?)\n",
    "####    https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "####    Actual labels vs predicted values (show best fit line with confidence_interval)  -- use different colors for different ML models\n",
    "####    Residuals vs predicted values\n",
    "####    Different regression metrics (R2, MSE, MAE, Variance explained etc)\n",
    "## Visualise box plots of test results from all models\n",
    "####    https://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/\n",
    "## Choose the best model and save for serving using Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#from sklearn.externals import joblib\n",
    "import joblib\n",
    "\n",
    "def save_model(save_path, model):\n",
    "    joblib.dump(model, save_path) # DIFF    \n",
    "\n",
    "def load_model(load_path):\n",
    "    my_model_loaded = joblib.load(load_path)\n",
    "    \n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "    \n",
    "\n",
    "# Function to get grid search results\n",
    "def get_hyperparameter_search_results(model, df_train, df_labels, search_type,\n",
    "                                      param_grid, param_distributions, n_iter, cv):\n",
    "    \"\"\"\n",
    "    Get hyperparameter search results\n",
    "    @params\n",
    "        model:        ML Model\n",
    "        df_train      Input features (pre-processed)\n",
    "        df_labels:    Labels\n",
    "        search_type:  \"grid\", \"randomized\"\n",
    "        param_grid:   List of dictionaries with parameters to be searched over\n",
    "    @returns\n",
    "        search_results: with following fields\n",
    "            [\"search\", \"best_params_\", \"best_estimator_\", \"cv_results_\"]\n",
    "    \"\"\"\n",
    "    search_results = {}\n",
    "    \n",
    "    ## train across 5 folds, that's a total of (12+6)*5=90 rounds of training\n",
    "    if search_type == \"grid\":\n",
    "        search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv,\n",
    "                              scoring='neg_mean_squared_error', return_train_score=True)\n",
    "    elif search_type == \"randomized\":\n",
    "        search = RandomizedSearchCV(estimator=model, param_distributions=param_distributions,\n",
    "                                    n_iter=n_iter, cv=cv, scoring='neg_mean_squared_error', random_state=42,\n",
    "                                    return_train_score=True)\n",
    "    else:\n",
    "        print(\"Invalid search type\")\n",
    "        return\n",
    "\n",
    "    search.fit(df_train, df_labels)\n",
    "\n",
    "    # Best estimator (hyperparameter combination) found\n",
    "    #search.best_params_\n",
    "    #search.best_estimator_\n",
    "\n",
    "    # score of each hyperparameter combination tested during the grid search\n",
    "    # cvres = grid_search.cv_results_\n",
    "    # for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    #    print(np.sqrt(-mean_score), params)\n",
    "    \n",
    "    search_results[\"search\"] = search\n",
    "    search_results[\"best_params_\"] = search.best_params_\n",
    "    search_results[\"best_estimator_\"] = search.best_estimator_\n",
    "    search_results[\"cv_results_\"] = search.cv_results_\n",
    "    \n",
    "    return search_results\n",
    "\n",
    "\n",
    "def plot_feature_importance(best_estimator, df_train):\n",
    "    \"\"\"\n",
    "    https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
    "    TODO: Can plot horizontal bars too\n",
    "    \"\"\"\n",
    "    #forest.fit(X, y)\n",
    "    #importances = forest.feature_importances_\n",
    "    X = df_train\n",
    "    importances = best_estimator.feature_importances_\n",
    "\n",
    "    #std = np.std([tree.feature_importances_ for tree in forest.estimators_],axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "    #print(\"Feature ranking:\")\n",
    "    #for f in range(X.shape[1]):\n",
    "    #    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "    # Plot the impurity-based feature importances of the forest\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(X.shape[1]), importances[indices], align=\"center\")\n",
    "    #        color=\"r\", yerr=std[indices], align=\"center\")\n",
    "    plt.xticks(range(X.shape[1]), indices)\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9546729000895465\n",
      "0.7601544488960017\n",
      "Scores: [0.9528555  0.95415046 0.96374648 0.95450051 0.94406339 0.95805711\n",
      " 0.95433024 0.95305073 0.95644868 0.95680724]\n",
      "Mean: 0.9548010349274805\n",
      "Standard deviation: 0.004693009386483896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\"\"\"\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(df_prepared, df_labels)\n",
    "\n",
    "df_predictions = lin_reg.predict(df_prepared)\n",
    "lin_mse = mean_squared_error(df_labels, df_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "print(lin_rmse)\n",
    "\n",
    "lin_mae = mean_absolute_error(df_labels, df_predictions)\n",
    "print(lin_mae)\n",
    "\n",
    "# Cross Validation\n",
    "lin_scores = cross_val_score(lin_reg, df_prepared, df_labels,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Decision Tree Regressor ====================\n",
      "Model: \n",
      "DecisionTreeRegressor(random_state=42)\n",
      "Default Model RMSE Score: 0.0\n",
      "======Best Parameters: ======\n",
      "{'max_depth': 5, 'max_features': 75}\n",
      "======Best Estimator: ======\n",
      "DecisionTreeRegressor(max_depth=5, max_features=75, random_state=42)\n",
      "====== Cross Validation Results ======\n",
      "0.08783881797824167 {'max_depth': 7, 'max_features': 52}\n",
      "0.027053482200331755 {'max_depth': 8, 'max_features': 61}\n",
      "-0.0 {'max_depth': 5, 'max_features': 75}\n",
      "0.549532477793607 {'max_depth': 8, 'max_features': 24}\n",
      "0.9518973459336154 {'max_depth': 3, 'max_features': 22}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from scipy.stats import randint\n",
    "\"\"\"\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg.fit(df_prepared, df_labels)\n",
    "\n",
    "df_predictions = tree_reg.predict(df_prepared)\n",
    "tree_mse = mean_squared_error(df_labels, df_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "print(tree_rmse)\n",
    "\n",
    "# Cross Validation\n",
    "scores = cross_val_score(tree_reg, df_prepared, df_labels,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(tree_rmse_scores)\n",
    "\"\"\"\n",
    "\n",
    "print(\"========= Decision Tree Regressor ====================\")\n",
    "default_model_dectree = DecisionTreeRegressor(random_state=42)\n",
    "default_model_dectree.fit(df_prepared, df_labels)\n",
    "df_predictions = default_model_dectree.predict(df_prepared)\n",
    "mse_default_model_dectree = mean_squared_error(df_labels, df_predictions)\n",
    "rmse_default_model_dectree = np.sqrt(mse_default_model_dectree)\n",
    "print(\"Model: \")\n",
    "print(default_model_dectree)\n",
    "print(\"Default Model RMSE Score: \" + str(rmse_default_model_dectree))\n",
    "\n",
    "\n",
    "model_dectree = DecisionTreeRegressor(random_state=42)\n",
    "param_distribs = {\n",
    "        'max_depth': randint(low=1, high=10),\n",
    "        'max_features': randint(low=1, high=80),\n",
    "    }\n",
    "search_results_dectree = get_hyperparameter_search_results(model=model_dectree, df_train=df_prepared,\n",
    "                                                           df_labels=df_labels, search_type=\"randomized\",\n",
    "                                                           param_grid=[], param_distributions=param_distribs,\n",
    "                                                           n_iter=5, cv=2)\n",
    "\n",
    "# Best estimator (hyperparameter combination) found\n",
    "print(\"======Best Parameters: ======\")\n",
    "print(search_results_dectree[\"best_params_\"])\n",
    "print(\"======Best Estimator: ======\")\n",
    "print(search_results_dectree[\"best_estimator_\"])\n",
    "\n",
    "print(\"====== Cross Validation Results ======\")\n",
    "# score of each hyperparameter combination tested during the grid search\n",
    "cvres = search_results_dectree[\"cv_results_\"]\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "        'max_features': randint(low=1, high=50),\n",
    "    }\n",
    "search = RandomizedSearchCV(model_dectree, param_distributions,\n",
    "                            n_iter=5, cv=2, scoring='neg_mean_squared_error', random_state=42,\n",
    "                            return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2, estimator=DecisionTreeRegressor(random_state=42),\n",
       "                   n_iter=5,\n",
       "                   param_distributions={'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1126e7dd8>},\n",
       "                   random_state=42, return_train_score=True,\n",
       "                   scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(df_prepared, df_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 39}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_features=39, random_state=42)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06370410496485601 {'max_features': 39}\n",
      "0.15309307250702864 {'max_features': 29}\n",
      "0.3749387036730768 {'max_features': 15}\n",
      "0.06826799734976707 {'max_features': 43}\n",
      "0.8275463258368158 {'max_features': 8}\n"
     ]
    }
   ],
   "source": [
    "cvres = search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Scores: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Mean: 0.0\n",
      "Standard deviation: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import randint\n",
    "from scipy import stats\n",
    "\n",
    "####################################################################\n",
    "####### Regression with set fixed values of model parameters #######\n",
    "forest_reg = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "forest_reg.fit(df_prepared, df_labels)\n",
    "df_predictions = forest_reg.predict(df_prepared)\n",
    "forest_mse = mean_squared_error(df_labels, df_predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "print(forest_rmse)\n",
    "####################################################################\n",
    "\n",
    "\n",
    "\n",
    "####################################################################\n",
    "##################### Cross Validation Scores ######################\n",
    "forest_scores = cross_val_score(forest_reg, df_prepared, df_labels,\n",
    "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)\n",
    "####################################################################\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "####################################################################\n",
    "############### Grid Search (to find best parameters) CV ###########\n",
    "param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "## train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error', return_train_score=True)\n",
    "grid_search.fit(df_prepared, df_labels)\n",
    "\n",
    "# Best estimator (hyperparameter combination) found\n",
    "grid_search.best_params_\n",
    "grid_search.best_estimator_\n",
    "\n",
    "# score of each hyperparameter combination tested during the grid search\n",
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)\n",
    "####################################################################\n",
    "\n",
    "\n",
    "####################################################################\n",
    "######### Randomized Search (to find best parameters) CV ###########\n",
    "param_distribs = {\n",
    "        'n_estimators': randint(low=1, high=200),\n",
    "        'max_features': randint(low=1, high=8),\n",
    "    }\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "rnd_search.fit(df_prepared, df_labels)\n",
    "\n",
    "cvres = rnd_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)\n",
    "####################################################################\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "####################################################################\n",
    "###################### Feature Importance ##########################\n",
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "#feature_importances\n",
    "attributes = numerical_attribs + categorical_attribs\n",
    "sorted(zip(feature_importances, attributes), reverse=True)\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_reg = SVR(kernel=\"linear\")\n",
    "svm_reg.fit(df_prepared, df_labels)\n",
    "df_predictions = svm_reg.predict(df_prepared)\n",
    "svm_mse = mean_squared_error(df_labels, df_predictions)\n",
    "svm_rmse = np.sqrt(svm_mse)\n",
    "svm_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A full pipeline with both preparation and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "full_pipeline_with_predictor = Pipeline([\n",
    "        (\"preparation\", full_pipeline),\n",
    "        (\"linear\", LinearRegression())\n",
    "    ])\n",
    "\n",
    "full_pipeline_with_predictor.fit(housing, housing_labels)\n",
    "full_pipeline_with_predictor.predict(some_data)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model comparison using test data results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "################## Final model and test RMSE #######################\n",
    "def get_test_results(strat_test_set, preprocessing_pipeline, final_model):\n",
    "    \"\"\"\n",
    "    @Params\n",
    "    strat_test_set: Test data\n",
    "    full_pipeline: Preprocessing pipeline\n",
    "    final_model: ML Model\n",
    "    \n",
    "    @Returns\n",
    "        test_results\n",
    "    \"\"\"\n",
    "    test_results = {}\n",
    "    #final_model = grid_search.best_estimator_\n",
    "\n",
    "    X_test = strat_test_set.drop(\"Price Label\", axis=1)\n",
    "    y_test = strat_test_set[\"Price Label\"].copy()\n",
    "\n",
    "    X_test_prepared = preprocessing_pipeline.transform(X_test)\n",
    "    final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "    final_mse = mean_squared_error(y_test, final_predictions)\n",
    "    final_rmse = np.sqrt(final_mse)\n",
    "\n",
    "    ## 95% confidence interval for the test RMSE\n",
    "    confidence = 0.95\n",
    "    squared_errors = (final_predictions - y_test) ** 2\n",
    "    mean = squared_errors.mean()\n",
    "    m = len(squared_errors)\n",
    "\n",
    "    confidence_interval_95 = np.sqrt(stats.t.interval(confidence, m - 1,\n",
    "                             loc=np.mean(squared_errors),\n",
    "                             scale=stats.sem(squared_errors)))\n",
    "    \n",
    "    test_results[\"labels\"] = y_test\n",
    "    test_results[\"predictions\"] = final_predictions\n",
    "    test_results[\"squared_errors\"] = squared_errors\n",
    "    test_results[\"mse\"] = final_mse\n",
    "    test_results[\"rmse\"] = final_rmse\n",
    "    test_results[\"interval_95%\"] = confidence_interval_95\n",
    "    \n",
    "    return test_results\n",
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16 * 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
